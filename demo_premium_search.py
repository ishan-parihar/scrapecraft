#!/usr/bin/env python3
"""
Premium Search Demo - Demonstrate advanced search capabilities
"""

import asyncio
import sys
import json
from datetime import datetime

# Add the backend directory to Python path
sys.path.insert(0, '/home/ishanp/Documents/GitHub/scrapecraft/backend')

async def demo_premium_search_service():
    """Demonstrate premium search service capabilities"""
    print("\n" + "="*60)
    print("ğŸ” PREMIUM SEARCH SERVICE DEMONSTRATION")
    print("="*60)
    
    try:
        from app.services.premium_scraping_service import PremiumScrapingService, EngineType
        
        async with PremiumScrapingService() as service:
            print("âœ… Premium scraping service initialized")
            
            # Test different search queries
            test_queries = [
                "cybersecurity threats 2024",
                "artificial intelligence trends",
                "open source intelligence tools"
            ]
            
            for query in test_queries:
                print(f"\nğŸ” Searching for: '{query}'")
                print("-" * 40)
                
                try:
                    # Use DuckDuckGo (most reliable without APIs)
                    results = await service.search_engine(
                        EngineType.DUCKDUCKGO, 
                        query, 
                        max_pages=1,
                        use_browser=False
                    )
                    
                    if results:
                        print(f"âœ… Found {len(results)} results")
                        
                        # Show top 3 results
                        for i, result in enumerate(results[:3], 1):
                            print(f"\n  {i}. {result.get('title', 'No title')}")
                            print(f"     ğŸ”— {result.get('url', 'No URL')}")
                            print(f"     ğŸ“„ {result.get('snippet', 'No snippet')[:100]}...")
                            print(f"     ğŸ¯ Relevance: {result.get('relevance_score', 0):.2f}")
                            print(f"     â­ Quality: {service._assess_quality(result):.2f}")
                            print(f"     ğŸ“‚ Type: {service._classify_content(result)}")
                    else:
                        print("âŒ No results found")
                        
                except Exception as e:
                    print(f"âŒ Search failed: {e}")
            
            # Test multi-engine search
            print(f"\nğŸŒ Testing multi-engine search...")
            query = "machine learning security"
            
            try:
                multi_results = await service.multi_engine_search(
                    query, 
                    [EngineType.DUCKDUCKGO, EngineType.BRAVE],
                    use_browser=False
                )
                
                if multi_results:
                    print(f"âœ… Multi-engine found {len(multi_results)} unique results")
                    
                    # Show engine distribution
                    engine_counts = {}
                    for result in multi_results:
                        engine = result.get('engine', 'unknown')
                        engine_counts[engine] = engine_counts.get(engine, 0) + 1
                    
                    print("ğŸ“Š Results by engine:")
                    for engine, count in engine_counts.items():
                        print(f"  {engine}: {count} results")
                        
                    # Show best result
                    best_result = max(multi_results, key=lambda x: x.get('relevance_score', 0))
                    print(f"\nğŸ† Best result:")
                    print(f"  Title: {best_result.get('title', 'No title')}")
                    print(f"  URL: {best_result.get('url', 'No URL')}")
                    print(f"  Relevance: {best_result.get('relevance_score', 0):.2f}")
                    print(f"  Quality: {service._assess_quality(best_result):.2f}")
                    
                else:
                    print("âŒ No multi-engine results found")
                    
            except Exception as e:
                print(f"âŒ Multi-engine search failed: {e}")
                
    except Exception as e:
        print(f"âŒ Demo failed: {e}")

async def demo_premium_search_agent():
    """Demonstrate premium search agent capabilities"""
    print("\n" + "="*60)
    print("ğŸ¤– PREMIUM SEARCH AGENT DEMONSTRATION")
    print("="*60)
    
    try:
        from app.agents.specialized.collection.premium_search_agent import PremiumSearchAgent
        
        async with PremiumSearchAgent() as agent:
            print("âœ… Premium search agent initialized")
            print(f"ğŸ“‹ Agent ID: {agent.config.agent_id}")
            print(f"ğŸ¯ Role: {agent.config.role}")
            
            # Test supported engines
            engines = await agent.get_supported_engines()
            print(f"ğŸ” Supported engines: {engines}")
            
            # Test search execution
            input_data = {
                "query": "cybersecurity best practices 2024",
                "engines": ["duckduckgo", "brave"],
                "max_pages": 1,
                "use_browser": False,
                "investigation_id": "demo-investigation-001"
            }
            
            print(f"\nğŸ” Executing search: '{input_data['query']}'")
            print("=" * 40)
            
            result = await agent.execute(input_data)
            
            if result.success:
                data = result.data
                results = data.get("results", [])
                summary = data.get("summary", {})
                
                print(f"âœ… Search successful!")
                print(f"ğŸ“Š Total results: {len(results)}")
                print(f"â±ï¸ Execution time: {result.execution_time:.2f}s")
                print(f"ğŸ¯ Confidence: {result.confidence:.2f}")
                
                print("\nğŸ“ˆ Search Summary:")
                for key, value in summary.items():
                    if isinstance(value, dict):
                        print(f"  {key}:")
                        for sub_key, sub_value in value.items():
                            print(f"    {sub_key}: {sub_value}")
                    else:
                        print(f"  {key}: {value}")
                
                # Show top results
                if results:
                    print(f"\nğŸ” Top 3 Results:")
                    for i, result in enumerate(results[:3], 1):
                        print(f"\n  {i}. {result.get('title', 'No title')}")
                        print(f"     ğŸ”— {result.get('url', 'No URL')}")
                        print(f"     ğŸ¯ Relevance: {result.get('relevance_score', 0):.2f}")
                        print(f"     â­ Quality: {result.get('quality_score', 0):.2f}")
                        print(f"     ğŸ“‚ Type: {result.get('content_type', 'Unknown')}")
                        print(f"     ğŸ·ï¸  Entities: {result.get('extracted_entities', [])}")
                        print(f"     ğŸ” Engine: {result.get('engine', 'Unknown')}")
                        
                # Show metadata
                metadata = data.get("metadata", {})
                if metadata:
                    print(f"\nğŸ”§ Metadata:")
                    for key, value in metadata.items():
                        print(f"  {key}: {value}")
                        
            else:
                print(f"âŒ Search failed: {result.error_message}")
                
    except Exception as e:
        print(f"âŒ Agent demo failed: {e}")

async def demo_content_analysis():
    """Demonstrate content analysis capabilities"""
    print("\n" + "="*60)
    print("ğŸ“Š CONTENT ANALYSIS DEMONSTRATION")
    print("="*60)
    
    try:
        from app.services.premium_scraping_service import PremiumScrapingService
        
        service = PremiumScrapingService()
        
        # Test content classification
        test_results = [
            {
                "title": "Python Machine Learning Tutorial",
                "snippet": "Learn machine learning with Python libraries like scikit-learn and TensorFlow",
                "url": "https://github.com/ml-tutorial"
            },
            {
                "title": "Latest Cybersecurity News",
                "snippet": "Breaking news about cybersecurity threats and data breaches in 2024",
                "url": "https://news.example.com/cybersecurity"
            },
            {
                "title": "Artificial Intelligence - Wikipedia",
                "snippet": "Artificial intelligence (AI) is intelligence demonstrated by machines",
                "url": "https://en.wikipedia.org/wiki/Artificial_intelligence"
            }
        ]
        
        print("ğŸ“‚ Content Classification Results:")
        for i, result in enumerate(test_results, 1):
            content_type = service._classify_content(result)
            quality = service._assess_quality(result)
            relevance = service._calculate_relevance_score(result)
            
            print(f"\n  {i}. {result['title']}")
            print(f"     ğŸ“‚ Type: {content_type}")
            print(f"     â­ Quality: {quality:.2f}")
            print(f"     ğŸ¯ Relevance: {relevance:.2f}")
            
        # Test entity extraction
        print(f"\nğŸ·ï¸  Entity Extraction:")
        for i, result in enumerate(test_results, 1):
            entities = service._extract_entities(result)
            print(f"\n  {i}. {result['title']}")
            print(f"     ğŸ·ï¸  Entities: {entities}")
            
    except Exception as e:
        print(f"âŒ Content analysis demo failed: {e}")

async def main():
    """Run all demonstrations"""
    print("ğŸš€ STARTING PREMIUM SEARCH COMPREHENSIVE DEMO")
    print("=" * 60)
    print(f"â° Started at: {datetime.now().isoformat()}")
    print("ğŸ¯ Demonstrating advanced search without API dependencies")
    print("=" * 60)
    
    # Run demonstrations
    await demo_premium_search_service()
    await demo_premium_search_agent()
    await demo_content_analysis()
    
    print("\n" + "="*60)
    print("âœ… PREMIUM SEARCH DEMONSTRATION COMPLETED")
    print(f"â° Finished at: {datetime.now().isoformat()}")
    print("="*60)
    
    print("\nğŸ‰ KEY ACHIEVEMENTS:")
    print("âœ… Premium search service with multi-engine support")
    print("âœ… Advanced HTML parsing for Google, Bing, DuckDuckGo, Brave")
    print("âœ… Anti-detection measures and rate limiting")
    print("âœ… Content quality assessment and classification")
    print("âœ… Entity extraction and metadata enrichment")
    print("âœ… Browser automation infrastructure (Playwright)")
    print("âœ… Proxy rotation framework")
    print("âœ… Investigation context integration")
    print("âœ… WebSocket real-time updates")
    print("âœ… RESTful API endpoints")
    
    print("\nğŸš€ READY FOR PHASE 3 ENHANCEMENTS:")
    print("â€¢ Google & Bing direct scraping (bypassing APIs)")
    print("â€¢ Academic source integration (arXiv, Google Scholar)")
    print("â€¢ Social media scraping capabilities")
    print("â€¢ Advanced CAPTCHA solving")
    print("â€¢ Distributed scraping architecture")
    print("â€¢ AI-powered content analysis")

if __name__ == "__main__":
    asyncio.run(main())